# TransferLearning-Tasks
In this code , we now have implemented three kinds of common transfer learning tasks for mobile-setting backbones, i.e. semantic segmentation, object detection, and keypoint detection.

Furthermore, we have used those tasks to demonstrate the transferability of our RelativeNAS and some existing works (such as NASNet and DARTS) under the same settings, and we also release all trained models, so you can get the same quantitative results as we have stated in our paper. 

### Notes: We will include more tasks and methods in the future, so if you are interesting in this you can start it to keep you informed. 



## Citation
If you use our code in your research, please cite our [paper](https://arxiv.org/abs/2009.06193):
```
@article{tan2020relative,
  title={RelativeNAS: Relative Neural Architecture Search via Slow-Fast Learning},
  author={Tan, Hao and Cheng, Ran and Huang, Shihua and He, Cheng and Qiu, Changxiao and Yang, Fan and Luo, Ping},
  journal={arXiv preprint arXiv:2009.06193},
  year={2020}
}
